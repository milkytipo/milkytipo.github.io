<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Semantic | Zida&#39;s Homepage</title>
    <link>/tag/semantic/</link>
      <atom:link href="/tag/semantic/index.xml" rel="self" type="application/rss+xml" />
    <description>Semantic</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 24 Jun 2019 23:29:34 +0800</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Semantic</title>
      <link>/tag/semantic/</link>
    </image>
    
    <item>
      <title>Intelligent Robotic Navigation and Manipulation System</title>
      <link>/project/singapore-project/</link>
      <pubDate>Mon, 24 Jun 2019 23:29:34 +0800</pubDate>
      <guid>/project/singapore-project/</guid>
      <description>&lt;p&gt;Traditionally,  mobile robot often realized docking action with help of RFID or QR code. In autonomous factories,  to dynamically follow mobile target and then implement docking action is a pressing demand. Therefore, we aimed to develop a docking SLAM method that tracks moving objects with cm-grade docking accuracy for autonomous vehicles.&lt;/p&gt;
&lt;p&gt;We chose Mask-RCNN build on FPN and ResNet101 to generate object masks and chose ORB_SLAM2 as back-end to realize online docking system.  In order to track the moving object, we constructed an images fusion module to combine the masks of object and depth geometry segmentation, and used omnidirectional wheels to avoid large rotation under close range.&lt;/p&gt;
&lt;p&gt;Such a system could real-time segment out the target object from the camera images, and only extract feature points from the specific region. Without complicated mapping, the vehicle would dynamically locate and follow the target machine to dock into it.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
